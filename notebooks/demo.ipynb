{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32944476",
   "metadata": {},
   "source": [
    "# Market Regime Detection via Maximum Mean Discrepancy (MMD)\n",
    "\n",
    "This notebook applies a sliding window MMD two-sample test to detect\n",
    "distributional regime changes in SPY returns. Detected boundaries\n",
    "are validated against known market events (e.g., COVID-19 crash)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4cc32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports\n",
    "# =============================================================================\n",
    "\n",
    "import time\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from kta import rbf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from regime_detection.features import df, make_features\n",
    "from regime_detection.mmd import sliding_window_mmd\n",
    "from regime_detection.plots import (\n",
    "    find_regime_boundaries,\n",
    "    plot_regime_boundaries_summary,\n",
    "    plot_regime_detection_panel,\n",
    "    results_to_dataframe,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2537ce3c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Configuration\n",
    "# =============================================================================\n",
    "\n",
    "# Sliding window parameters\n",
    "WINDOW = 30  # days in each window (compare before vs after)\n",
    "STEP = 5  # days between successive windows\n",
    "N_PERMUTATIONS = 1000  # permutations for null distribution (reduce for speed)\n",
    "\n",
    "# Boundary detection parameters\n",
    "METRIC = \"std_from_null\"  # metric to threshold: 'std_from_null', 'mmd', 'kta_val'\n",
    "THRESHOLD = 10.0  # values above this are flagged as boundaries\n",
    "MIN_GAP_DAYS = 20  # merge detections within this many days\n",
    "\n",
    "# Feature selection\n",
    "FEATURE_GROUP = \"base\"  # options: 'base', 'intraday_shape', 'vol_structure', 'all'\n",
    "\n",
    "# Standardization\n",
    "STANDARDIZE = True  # Use StandardScaler to standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5cfe30",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Data Preparation\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def prepare_signal(\n",
    "    feature_group: str = \"base\",\n",
    "    standardize: bool = True,\n",
    ") -> tuple[np.ndarray, pd.DatetimeIndex]:\n",
    "    \"\"\"\n",
    "    Load and prepare feature matrix for MMD analysis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_group : str\n",
    "        Name of feature group to load\n",
    "    standardize : bool\n",
    "        If True, standardize features to zero mean and unit variance.\n",
    "        Recommended for kernel methods to prevent scale-dominated distances.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    signal : np.ndarray\n",
    "        Feature matrix (n_samples, n_features)\n",
    "    index : pd.DatetimeIndex\n",
    "        Corresponding dates\n",
    "    \"\"\"\n",
    "    features = make_features(feature_group)\n",
    "    print(f\"Feature group: {feature_group}\")\n",
    "    print(f\"Features: {list(features.columns)}\")\n",
    "    print(f\"Shape: {features.shape}\")\n",
    "    print(f\"Date range: {features.index[0].date()} to {features.index[-1].date()}\")\n",
    "\n",
    "    values = features.values\n",
    "\n",
    "    if standardize:\n",
    "        scalar = StandardScaler()\n",
    "        values = scalar.fit_transform(values)\n",
    "        print(\"Standardization: Applied (zero mean, unit variance)\")\n",
    "    else:\n",
    "        print(\"Standardization: None (raw features)\")\n",
    "\n",
    "    return values, features.index\n",
    "\n",
    "\n",
    "def compute_kernel_bandwidth(signal: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute RBF bandwidth using median heuristic.\n",
    "    \"\"\"\n",
    "    sigma = np.median(np.abs(signal - np.median(signal)))\n",
    "    gamma = 1.0 / (2 * sigma**2)\n",
    "    print(f\"Median heuristic: sigma={sigma:.6f}, gamma={gamma:.4f}\")\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01589f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Run Analysis\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def run_sliding_window_analysis(\n",
    "    signal: np.ndarray,\n",
    "    kernel_fn,\n",
    "    kernel_params: Dict,\n",
    "    window: int,\n",
    "    step: int,\n",
    "    n_permutations: int,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Execute sliding window MMD with timing.\n",
    "    \"\"\"\n",
    "    n_windows = (len(signal) - 2 * window) // step\n",
    "    print(\"\\nRunning sliding window MMD...\")\n",
    "    print(f\"  Window size: {window} days\")\n",
    "    print(f\"  Step size: {step} days\")\n",
    "    print(f\"  Permutations: {n_permutations}\")\n",
    "    print(f\"  Estimated windows: ~{n_windows}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    results = sliding_window_mmd(\n",
    "        data=signal,\n",
    "        kernel_fn=kernel_fn,\n",
    "        kernel_params=kernel_params,\n",
    "        window=window,\n",
    "        step=step,\n",
    "        n_permutations=n_permutations,\n",
    "    )\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"  Completed in {elapsed:.1f}s ({len(results)} windows)\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18af9c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Validation\n",
    "# =============================================================================\n",
    "\n",
    "# Known market events for validation (approximate dates)\n",
    "KNOWN_EVENTS = {\n",
    "    \"COVID Crash\": (\"2020-02-19\", \"2020-03-23\"),\n",
    "    \"COVID Recovery\": (\"2020-03-24\", \"2020-08-31\"),\n",
    "    \"2022 Drawdown Start\": (\"2022-01-03\", \"2022-01-31\"),\n",
    "    \"2022 Bottom\": (\"2022-09-01\", \"2022-10-31\"),\n",
    "    \"2023 Rally\": (\"2023-01-01\", \"2023-03-31\"),\n",
    "}\n",
    "\n",
    "\n",
    "def validate_against_known_events(\n",
    "    results_df: pd.DataFrame,\n",
    "    events: Dict[str, tuple] = KNOWN_EVENTS,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Check if detected signals correspond to known market events.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Validation Against Known Events\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    validation_rows = []\n",
    "\n",
    "    for event_name, (start, end) in events.items():\n",
    "        try:\n",
    "            period = results_df.loc[start:end]\n",
    "            if len(period) == 0:\n",
    "                print(f\"\\n{event_name}: No data in range {start} to {end}\")\n",
    "                continue\n",
    "\n",
    "            max_std = period[\"std_from_null\"].max()\n",
    "            max_mmd = period[\"mmd\"].max()\n",
    "            max_kta = period[\"kta_val\"].max()\n",
    "            max_date = period[\"std_from_null\"].idxmax()\n",
    "\n",
    "            print(f\"\\n{event_name} ({start} to {end}):\")\n",
    "            print(f\"  Peak std_from_null: {max_std:.2f} on {max_date.date()}\")\n",
    "            print(f\"  Peak MMD: {max_mmd:.4f}\")\n",
    "            print(f\"  Peak KTA: {max_kta:.3f}\")\n",
    "\n",
    "            validation_rows.append(\n",
    "                {\n",
    "                    \"event\": event_name,\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                    \"peak_std\": max_std,\n",
    "                    \"peak_mmd\": max_mmd,\n",
    "                    \"peak_kta\": max_kta,\n",
    "                    \"peak_date\": max_date,\n",
    "                },\n",
    "            )\n",
    "        except KeyError:\n",
    "            print(f\"\\n{event_name}: Date range outside data\")\n",
    "\n",
    "    return pd.DataFrame(validation_rows)\n",
    "\n",
    "\n",
    "def summarize_boundaries(\n",
    "    boundaries: pd.DatetimeIndex,\n",
    "    results_df: pd.DataFrame,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Print summary of detected regime boundaries.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Detected Regime Boundaries (n={len(boundaries)})\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    if len(boundaries) == 0:\n",
    "        print(\"No boundaries detected. Consider lowering the threshold.\")\n",
    "        return\n",
    "\n",
    "    for i, b in enumerate(boundaries, 1):\n",
    "        row = results_df.loc[b]\n",
    "        print(\n",
    "            f\"  {i}. {b.date()}  |  std={row['std_from_null']:.1f}  |  MMD={row['mmd']:.4f}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63636661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Main Execution\n",
    "# =============================================================================\n",
    "\n",
    "# --- Prepare data ---\n",
    "signal, date_index = prepare_signal(FEATURE_GROUP, standardize=STANDARDIZE)\n",
    "gamma = compute_kernel_bandwidth(signal)\n",
    "kernel_params = {\"gamma\": gamma}\n",
    "\n",
    "# --- Run MMD analysis ---\n",
    "results = run_sliding_window_analysis(\n",
    "    signal=signal,\n",
    "    kernel_fn=rbf,\n",
    "    kernel_params=kernel_params,\n",
    "    window=WINDOW,\n",
    "    step=STEP,\n",
    "    n_permutations=N_PERMUTATIONS,\n",
    ")\n",
    "\n",
    "# --- Convert to DataFrame with dates ---\n",
    "results_df = results_to_dataframe(results, date_index)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Results Summary Statistics\")\n",
    "print(\"=\" * 60)\n",
    "print(results_df[[\"mmd\", \"std_from_null\", \"kta_val\"]].describe().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39920adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Validation Against Known Events\n",
    "# =============================================================================\n",
    "\n",
    "validation_df = validate_against_known_events(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4017911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Detect Boundaries\n",
    "# =============================================================================\n",
    "\n",
    "boundaries = find_regime_boundaries(\n",
    "    results_df,\n",
    "    metric=METRIC,\n",
    "    threshold=THRESHOLD,\n",
    "    min_gap_days=MIN_GAP_DAYS,\n",
    ")\n",
    "summarize_boundaries(boundaries, results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b78737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Main Figure: 4-Panel Regime Detection\n",
    "# =============================================================================\n",
    "\n",
    "fig1, axes1 = plot_regime_detection_panel(\n",
    "    price_series=df[\"Close\"],\n",
    "    results_df=results_df,\n",
    "    metric=METRIC,\n",
    "    threshold=THRESHOLD,\n",
    "    min_gap_days=MIN_GAP_DAYS,\n",
    "    title=f\"Market Regime Detection via MMD (window={WINDOW}d, {FEATURE_GROUP} features)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0888d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Summary Figure: Price with Boundaries\n",
    "# =============================================================================\n",
    "\n",
    "fig2, ax2 = plot_regime_boundaries_summary(\n",
    "    price_series=df[\"Close\"],\n",
    "    results_df=results_df,\n",
    "    boundaries=boundaries,\n",
    "    window_days=WINDOW,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Threshold Sensitivity\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Threshold Sensitivity Analysis\")\n",
    "print(\"-\" * 40)\n",
    "for thresh in [5.0, 8.0, 10.0, 12.0, 15.0, 20.0]:\n",
    "    b = find_regime_boundaries(\n",
    "        results_df,\n",
    "        threshold=thresh,\n",
    "        min_gap_days=MIN_GAP_DAYS,\n",
    "    )\n",
    "    print(f\"  threshold={thresh:5.1f}  â†’  {len(b):2d} boundaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044e9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py:percent,ipynb",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
